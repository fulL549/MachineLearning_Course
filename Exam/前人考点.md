## version1

机器学习：
六道大题，每道大题有3个小问
没有深度学习模型，只需要知道什么叫深度学习和神经网络，怎样训练

### 一、回归：线性回归和逻辑回归

目标函数，怎样求，参数怎样建模，梯度下降法（优缺点），不一定找到最优，学习率与目标函数的关系，不需要推导偏差什么的

逻辑回归如何建模，是什么模型，目标函数，怎样定义，怎样求解参数，参数如何更新，引入什么项

### 二、集成学习

两个算法，BAG、BOOST

什么叫集成学习，什么意思，为什么效果好，主要了解两个算法，目标函数（大多数投票），Bagging算法获得多分类器，采样得到数据集，每个数据集得到一个分类器，判断样本类别，大多数投票判断什么类别，有放置采样，基本思想

Boosting：获得多个机器分类器，集成起来得到好的分类器，每个样本有权重，初始化相同，每一轮采样分类错误的权重加大，正确的权重变小，线性集成，每个分类器有权重

### 三、支持向量机

知道基本原理、为什么引入改进算法，怎样改进，不需要推导

找出分界面，使距离最大，拉格朗日求解了解一下，变种算法有哪些，推导不用记，因子，引入和函数要知道

### 四、聚类

两个算法，kmeans算法，高斯混合聚类算法

K-means步骤那几步，优缺点，怎么决定参数，有什么含义，怎么初始化，目标函数是什么，为什么能够终止，什么结果是kmeans聚合出来的结果

高斯混合聚类：怎么更新均值和方差，参数如何更新

### 五、EM算法

原理和推导，应用范围，现实生活

思想、理论要掌握，目标函数怎样理解，隐变量和参数，推导过程要掌握，看第一个例子，第二个不用看

### 六、推荐系统算法


## version2

### 线性回归，逻辑回归

损失函数，如何通过梯度下降法求解参数，最优参数表达式（如果存在）

### 过拟合

什么是过拟合，降低过拟合风险的方法

### 训练方法

训练集-矫正集-测试集，留出法（Hold-out method）, Repeated hold-out method, k-fold cross-validation, k-fold cross-validation with validation and test sets, Bootstrap method

### 决策树

熵的求解，条件熵的求解，求解对应属性的信息增益，决策树的构建

### SVM

SVM的基本思想，SVM的损失函数，SVM中的核函数

### PCA

PCA的基本思想，PCA的不同理解角度，PCA的推导过程

### 聚类

K-Means聚类的思想、步骤、目标函数，K的选取问题，高斯混合聚类算法的思想和步骤

### EM算法

EM算法中的E步和M步

### 推荐系统

基于矩阵分解的推荐系统，基于用户的协同推荐，基于商品的协同推荐，冷启动问题，数据稀疏的问题


## version3

问答题：六道大题，每道大题有两三道小题，不用带计算器

1. **线性回归**
   1. 损失函数的构建，推导（求偏导要会）
2. **线性分类器**
   1. 逻辑回归、Sigmoid函数、判别边界
   2. 交叉熵损失函数、交叉熵损失函数的梯度求解
   3. Softmax函数
3. 从概率角度理解回归和分类问题
4. **过拟合和正则化**
   1. 过拟合问题的概念和解决，欠拟合问题
   2. 正则化项
5. **支持向量机（爹）**
   1. 最大边界分类器：函数的定义、如何推导、最终的数学公式
   2. 软的最大边界分类器：松弛变量
   3. 支持向量机的推导：核函数
6. 神经网络
   1. 激活函数、了解典型神经网络
7. 神经网络的优化和训练技巧
   1. Adam
8. Bagging & Boosting
9. **PCA（爹）**
   1. 最小化重构误差的推导、证明
   2. 最大化方差的推导、证明
   3. （了解）奇异值分解的推导
10. **聚类：K-Means**
    1. K-means 的目标函数、基本步骤和时间复杂度
11. **决策树**
    1. 自己学
12. **EM 算法（爷爷）**
    1. 用高斯混合模型的例子讲明白 E 步骤和 M 步骤
    2. 了解 EM 和 K-Means 的关系
13. **推荐系统（爹）**
    1. 基于内容的推荐系统：三大步骤（Plan of Action）、优点和缺点
    2. 基于协同滤波的推荐系统：三大步骤、相似性计算方法、基于用户的协同滤波和基于项的协同滤波的区别
    3. 冷启动问题、稀疏性问题
14. PageRank、社区发现、关联规则挖掘、LSH 不考

